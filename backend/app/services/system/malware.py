#!/usr/bin/env python3
"""
Advanced Enterprise Malware Propagation Detection & Response System (EMPDRS)
Enhanced Features:
- Real-time static, behavioral, and network analysis with propagation detection
- Self-updating machine learning-based heuristics with YARA + custom rules
- Advanced process injection & memory manipulation detection
- Fileless malware detection with in-memory scanning
- Lateral movement & propagation vector identification
- C2 & beaconing detection with traffic pattern analysis
- Network segmentation & autonomous containment
- Cross-platform (Windows/macOS/Linux) with native optimizations
- Minimal external dependencies (pure Python where possible)
- Secure rollback capabilities with system snapshots
- Comprehensive forensics with timeline reconstruction
"""

import os
import sys
import json
import time
import signal
import hashlib
import socket
import struct
import multiprocessing as mp
import threading
import queue
import math
import re
import uuid
import sqlite3
import pickle
import base64
import ipaddress
import random
import gzip
import tempfile
from datetime import datetime, timedelta
from collections import defaultdict, deque, Counter
import logging
import platform
import socketio # Added
import zlib
import subprocess
import urllib.request
import urllib.parse
import io
import traceback

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("empdrs.log"), logging.StreamHandler()],
)
logger = logging.getLogger("EMPDRS")


# Setup dashboard communication
class DashboardClient:
    """Socket.IO client for dashboard communication"""

    def __init__(self, server_url="http://localhost:8000", namespace="/malware_events"):
        self.server_url = server_url
        self.namespace = namespace
        self.sio = socketio.Client(logger=True, engineio_logger=True)
        self.connected = False
        self._connect_thread = None
        self.stop_event = None # Added for graceful shutdown
        self._setup_handlers()

    def _setup_handlers(self):
        @self.sio.event
        def connect():
            logger.info(f"EMPDRS: Successfully connected to Socket.IO server at {self.server_url} in namespace {self.namespace}")
            self.connected = True

        @self.sio.event
        def connect_error(data):
            logger.error(f"EMPDRS: Socket.IO connection failed: {data}")
            self.connected = False

        @self.sio.event
        def disconnect():
            logger.info("EMPDRS: Disconnected from Socket.IO server.")
            self.connected = False

    def connect(self, stop_event_ref=None): # Added stop_event_ref
        self.stop_event = stop_event_ref
        if self.connected:
            logger.info("EMPDRS: Already connected or connection attempt in progress.")
            return self
        
        if self._connect_thread and self._connect_thread.is_alive():
            logger.info("EMPDRS: Connection attempt already in progress.")
            return self

        def attempt_connection():
            while not (self.stop_event and self.stop_event.is_set()):
                if self.connected:
                    break
                try:
                    logger.info(f"EMPDRS: Attempting to connect to Socket.IO server at {self.server_url}...")
                    self.sio.connect(self.server_url, namespaces=[self.namespace], wait_timeout=10)
                    if self.sio.connected:
                         break 
                    else: 
                         logger.warning(f"EMPDRS: sio.connect call returned but not connected. Retrying in 10s.")
                         time.sleep(10)

                except socketio.exceptions.ConnectionError as e:
                    logger.error(f"EMPDRS: Socket.IO ConnectionError: {e}. Retrying in 10 seconds.")
                    time.sleep(10)
                except Exception as e:
                    logger.error(f"EMPDRS: Unexpected error during Socket.IO connection: {e}. Retrying in 10 seconds.")
                    time.sleep(10)
            logger.info("EMPDRS: Connection attempt loop terminated.")

        self._connect_thread = threading.Thread(target=attempt_connection, daemon=True)
        self._connect_thread.start()
        return self

    def emit(self, event_name, data):
        if self.sio.connected and self.namespace in self.sio.namespaces:
            try:
                self.sio.emit(event_name, data, namespace=self.namespace)
                logger.debug(f"EMPDRS: Emitted event '{event_name}' to namespace '{self.namespace}' with data: {str(data)[:100]}...")
            except Exception as e:
                logger.error(f"EMPDRS: Error emitting event '{event_name}': {e}")
        else:
            logger.warning(f"EMPDRS: Cannot emit event '{event_name}', not connected to Socket.IO server or namespace '{self.namespace}' not available.")

    def disconnect_client(self):
        if self.sio.connected:
            self.sio.disconnect()

# Initialize dashboard client (adjust server_url if your main backend Socket.IO is elsewhere)
# The namespace '/malware_events' is chosen to segregate these events.
sio_dashboard_client = DashboardClient(server_url="http://localhost:8000", namespace="/malware_events")
# In a real script, you'd likely create a threading.Event() for stop_event_ref
# global_stop_event = threading.Event()
# sio_dashboard_client.connect(stop_event_ref=global_stop_event)
# For now, connect without it, or the main script part needs to manage the event.
sio_dashboard_client.connect()

# Platform detection
PLATFORM = platform.system()
IS_WINDOWS = PLATFORM == "Windows"
IS_MACOS = PLATFORM == "Darwin"
IS_LINUX = PLATFORM == "Linux"


# ML Helper functions for malware detection algorithms
class MLHelper:
    """Machine learning helper functions without external dependencies"""

    @staticmethod
    def calculate_entropy(data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0

        entropy = 0
        counts = Counter(data)
        data_len = len(data)

        for count in counts.values():
            p_x = count / data_len
            entropy += -p_x * math.log2(p_x)

        return entropy

    @staticmethod
    def random_forest_predict(features, trees):
        """Simple random forest implementation"""
        votes = []
        for tree in trees:
            node = tree
            while "leaf" not in node:
                if features[node["feature"]] <= node["threshold"]:
                    node = node["left"]
                else:
                    node = node["right"]
            votes.append(node["leaf"])

        # Return majority vote
        return Counter(votes).most_common(1)[0][0]

    @staticmethod
    def isolation_forest_score(features, trees):
        """Calculate anomaly score using isolation forest"""
        path_lengths = []
        for tree in trees:
            node = tree
            path_length = 0
            while "leaf" not in node:
                path_length += 1
                if features[node["feature"]] <= node["threshold"]:
                    node = node["left"]
                else:
                    node = node["right"]
            path_lengths.append(path_length)

        # Normalize and return anomaly score (closer to 1 is more anomalous)
        avg_path = sum(path_lengths) / len(path_lengths)
        return 2 ** (-avg_path / (len(features) * 0.5))

    @staticmethod
    def detect_anomaly(sample, history, threshold=2.0):
        """Z-score based anomaly detection"""
        if not history:
            return False

        mean = sum(history) / len(history)
        std_dev = math.sqrt(sum((x - mean) ** 2 for x in history) / len(history))

        # Avoid division by zero
        if std_dev < 0.0001:
            std_dev = 0.0001

        z_score = abs(sample - mean) / std_dev
        return z_score > threshold


class DatabaseManager:
    """SQLite database for persistent storage"""

    def __init__(self, db_path="empdrs.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """Initialize database with required tables"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        # Create tables if they don't exist
        c.execute(
            """
        CREATE TABLE IF NOT EXISTS alerts (
            id TEXT PRIMARY KEY,
            timestamp TEXT,
            type TEXT,
            severity TEXT,
            source TEXT,
            data TEXT,
            resolved INTEGER DEFAULT 0
        )
        """
        )

        c.execute(
            """
        CREATE TABLE IF NOT EXISTS threat_intel (
            type TEXT,
            value TEXT,
            source TEXT,
            added_time TEXT,
            PRIMARY KEY (type, value)
        )
        """
        )

        c.execute(
            """
        CREATE TABLE IF NOT EXISTS system_baseline (
            path TEXT PRIMARY KEY,
            hash TEXT,
            size INTEGER,
            perms INTEGER,
            mod_time REAL,
            baseline_date TEXT
        )
        """
        )

        c.execute(
            """
        CREATE TABLE IF NOT EXISTS propagation_events (
            id TEXT PRIMARY KEY,
            timestamp TEXT,
            source_host TEXT,
            source_ip TEXT,
            target_ip TEXT,
            vector TEXT,
            malware_family TEXT,
            blocked INTEGER DEFAULT 0,
            details TEXT
        )
        """
        )

        conn.commit()
        conn.close()

    def add_alert(self, alert_type, severity, source, data):
        """Add a new alert to the database"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        alert_id = str(uuid.uuid4())
        timestamp = datetime.utcnow().isoformat()

        c.execute(
            "INSERT INTO alerts VALUES (?, ?, ?, ?, ?, ?, ?)",
            (alert_id, timestamp, alert_type, severity, source, json.dumps(data), 0),
        )

        conn.commit()
        conn.close()
        return alert_id

    def get_alerts(self, limit=100, resolved=False):
        """Get recent alerts from the database"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        c = conn.cursor()

        c.execute(
            "SELECT * FROM alerts WHERE resolved = ? ORDER BY timestamp DESC LIMIT ?",
            (1 if resolved else 0, limit),
        )

        results = [dict(row) for row in c.fetchall()]
        conn.close()

        # Parse JSON data
        for row in results:
            row["data"] = json.loads(row["data"])

        return results

    def add_threat_intel(self, intel_type, value, source="local"):
        """Add threat intelligence indicator"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        timestamp = datetime.utcnow().isoformat()

        try:
            c.execute(
                "INSERT OR REPLACE INTO threat_intel VALUES (?, ?, ?, ?)",
                (intel_type, value, source, timestamp),
            )
            conn.commit()
        except sqlite3.Error as e:
            logger.error(f"Database error: {e}")
        finally:
            conn.close()

    def get_threat_intel(self, intel_type=None):
        """Get threat intelligence indicators"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        c = conn.cursor()

        if intel_type:
            c.execute("SELECT * FROM threat_intel WHERE type = ?", (intel_type,))
        else:
            c.execute("SELECT * FROM threat_intel")

        results = [dict(row) for row in c.fetchall()]
        conn.close()
        return results

    def add_system_file(self, path, hash_value, size, perms, mod_time):
        """Add or update system file baseline"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        baseline_date = datetime.utcnow().isoformat()

        c.execute(
            "INSERT OR REPLACE INTO system_baseline VALUES (?, ?, ?, ?, ?, ?)",
            (path, hash_value, size, perms, mod_time, baseline_date),
        )

        conn.commit()
        conn.close()

    def get_system_file(self, path):
        """Get system file baseline info"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        c = conn.cursor()

        c.execute("SELECT * FROM system_baseline WHERE path = ?", (path,))
        result = c.fetchone()

        conn.close()
        return dict(result) if result else None

    def add_propagation_event(
        self,
        source_host,
        source_ip,
        target_ip,
        vector,
        malware_family,
        details,
        blocked=False,
    ):
        """Record a malware propagation attempt"""
        conn = sqlite3.connect(self.db_path)
        c = conn.cursor()

        event_id = str(uuid.uuid4())
        timestamp = datetime.utcnow().isoformat()

        c.execute(
            "INSERT INTO propagation_events VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
            (
                event_id,
                timestamp,
                source_host,
                source_ip,
                target_ip,
                vector,
                malware_family,
                1 if blocked else 0,
                json.dumps(details),
            ),
        )

        conn.commit()
        conn.close()
        return event_id


class ThreatIntel:
    """Enhanced threat intelligence with local and remote feeds"""

    def __init__(self, db_manager):
        self.db = db_manager
        self.cache = {
            "hashes": set(),
            "ips": set(),
            "domains": set(),
            "urls": set(),
            "patterns": set(),
        }
        self.last_update = None
        self.update_interval = 3600  # 1 hour
        self._load_from_db()

    def _load_from_db(self):
        """Load intelligence from database to cache"""
        for item in self.db.get_threat_intel():
            if item["type"] in self.cache:
                self.cache[item["type"]].add(item["value"])

    def update(self):
        """Update threat intelligence from all sources"""
        current_time = time.time()

        # Only update if interval has passed
        if self.last_update and (
            current_time - self.last_update < self.update_interval
        ):
            return

        self._update_embedded()
        self._update_from_local_sources()
        self._try_update_from_remote()

        self.last_update = current_time
        sio_dashboard_client.emit(
            "threat_intel_update",
            {"status": "success", "count": self._count_indicators()},
        )

    def _update_embedded(self):
        """Update with embedded intelligence"""
        # Sample malicious hashes
        embedded_intel = {
            "hashes": [
                "a94a8fe5ccb19ba61c4c0873d391e987982fbbd3",  # Example SHA1
                "d41d8cd98f00b204e9800998ecf8427e",  # Example MD5
                "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",  # Example SHA256
            ],
            "ips": [
                "192.168.1.100",
                "10.10.10.10",
            ],
            "domains": [
                "malicious.example.com",
                "c2server.example.org",
            ],
            "urls": [
                "http://malware.example.com/payload.exe",
                "https://badsite.example.org/download?id=malicious",
            ],
            "patterns": [
                r"powershell\.exe.*-enc\s+[A-Za-z0-9+/=]{100,}",
                r"cmd\.exe.*certutil.*-decode",
                r"regsvr32\.exe.*/i:http",
            ],
        }

        # Add to database and cache
        for intel_type, values in embedded_intel.items():
            for value in values:
                self.add_indicator(intel_type, value, "embedded")

    def _update_from_local_sources(self):
        """Update from local intelligence sources"""
        # Windows-specific local sources
        if IS_WINDOWS:
            # Parse Windows Defender detections
            try:
                defender_path = os.path.expandvars(
                    "%ProgramData%\\Microsoft\\Windows Defender\\Scans\\History\\Service\\DetectionHistory"
                )
                if os.path.exists(defender_path):
                    for root, _, files in os.walk(defender_path):
                        for file in files:
                            if file.endswith(".txt"):
                                with open(
                                    os.path.join(root, file), "r", errors="ignore"
                                ) as f:
                                    content = f.read()
                                    # Extract hashes and add to intel
                                    hash_matches = re.findall(
                                        r"\b[a-fA-F0-9]{32,64}\b", content
                                    )
                                    for hash_val in hash_matches:
                                        self.add_indicator(
                                            "hashes", hash_val, "windows_defender"
                                        )
            except Exception as e:
                logger.warning(f"Failed to parse Windows Defender data: {e}")

        # Linux-specific local sources
        if IS_LINUX:
            # Check ClamAV logs if available
            try:
                log_paths = [
                    "/var/log/clamav/freshclam.log",
                    "/var/log/clamav/clamav.log",
                ]
                for log_path in log_paths:
                    if os.path.exists(log_path):
                        with open(log_path, "r", errors="ignore") as f:
                            content = f.read()
                            # Extract potential malicious indicators
                            hash_matches = re.findall(
                                r"\b[a-fA-F0-9]{32,64}\b", content
                            )
                            for hash_val in hash_matches:
                                self.add_indicator("hashes", hash_val, "clamav")
            except Exception as e:
                logger.warning(f"Failed to parse ClamAV logs: {e}")

    def _try_update_from_remote(self):
        """Try to update from remote sources if available"""
        try:
            # Try to download a sample open-source threat feed
            # Use a simple URL that doesn't require authentication
            urls = [
                "https://raw.githubusercontent.com/stamparm/ipsum/master/ipsum.txt",  # IP blocklist
                "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts",  # Malicious domains
            ]

            for url in urls:
                try:
                    with urllib.request.urlopen(url, timeout=5) as response:
                        content = response.read().decode("utf-8", errors="ignore")

                        # Process IPs
                        if "ipsum.txt" in url:
                            for line in content.splitlines():
                                if line and not line.startswith("#"):
                                    ip = line.split()[0]
                                    if self._is_valid_ip(ip):
                                        self.add_indicator("ips", ip, "ipsum")

                        # Process hosts file
                        elif "hosts" in url:
                            for line in content.splitlines():
                                if line and not line.startswith("#"):
                                    parts = line.strip().split()
                                    if len(parts) >= 2 and parts[0] in (
                                        "0.0.0.0",
                                        "127.0.0.1",
                                    ):
                                        domain = parts[1]
                                        self.add_indicator(
                                            "domains", domain, "stevenblack_hosts"
                                        )
                except Exception as e:
                    logger.warning(f"Failed to fetch threat feed from {url}: {e}")

        except Exception as e:
            logger.warning(f"Remote threat feed update failed: {e}")

    def add_indicator(self, indicator_type, value, source="local"):
        """Add a new indicator to threat intelligence"""
        if indicator_type in self.cache:
            self.cache[indicator_type].add(value)
            self.db.add_threat_intel(indicator_type, value, source)

    def _is_valid_ip(self, ip):
        """Check if a string is a valid IP address"""
        try:
            ipaddress.ip_address(ip)
            return True
        except ValueError:
            return False

    def _count_indicators(self):
        """Count total indicators in cache"""
        return sum(len(indicators) for indicators in self.cache.values())

    def check_hash(self, hash_value):
        """Check if a hash exists in threat intelligence"""
        return hash_value in self.cache["hashes"]

    def check_ip(self, ip):
        """Check if an IP exists in threat intelligence"""
        if ip in self.cache["ips"]:
            return True

        # Check IP ranges
        try:
            ip_obj = ipaddress.ip_address(ip)
            for ip_range in self.cache["ips"]:
                if "/" in ip_range:  # CIDR notation
                    try:
                        network = ipaddress.ip_network(ip_range, strict=False)
                        if ip_obj in network:
                            return True
                    except ValueError:
                        pass
        except ValueError:
            pass

        return False

    def check_domain(self, domain):
        """Check if a domain exists in threat intelligence"""
        if domain in self.cache["domains"]:
            return True

        # Check for partial domain matches (subdomains)
        domain_parts = domain.split(".")
        for i in range(len(domain_parts) - 1):
            partial = ".".join(domain_parts[i:])
            if partial in self.cache["domains"]:
                return True

        return False

    def check_url(self, url):
        """Check if a URL matches threat intelligence"""
        if url in self.cache["urls"]:
            return True

        # Parse URL for domain check
        try:
            parsed = urllib.parse.urlparse(url)
            if self.check_domain(parsed.netloc):
                return True
        except Exception:
            pass

        return False

    def check_pattern(self, text):
        """Check if text matches any malicious patterns"""
        for pattern in self.cache["patterns"]:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False


class SignatureEngine:
    """YARA-inspired signature engine without external dependencies"""

    def __init__(self):
        self.rules = []
        self._load_embedded_rules()

    def _load_embedded_rules(self):
        """Load embedded detection rules"""
        self.rules.extend(
            [
                {
                    "name": "suspicious_pe_header",
                    "description": "Detects suspicious PE file header characteristics",
                    "type": "binary",
                    "patterns": [
                        (b"MZ", 0),  # DOS header
                        (b"PE\x00\x00", None),  # PE header
                    ],
                    "condition": lambda m: m[0] and m[1] and (m[1] - m[0]) < 1024,
                },
                {
                    "name": "embedded_executable",
                    "description": "Detects embedded executable within another file",
                    "type": "binary",
                    "patterns": [(b"MZ", 0x200)],  # DOS header not at start of file
                    "condition": lambda m: m[0] is not None,
                },
                {
                    "name": "powershell_encoded_command",
                    "description": "Detects PowerShell encoded commands",
                    "type": "text",
                    "patterns": [
                        (
                            r"powershell.*-e(?:nc|ncodedcommand)\s+[A-Za-z0-9+/=]{10,}",
                            None,
                        )
                    ],
                    "condition": lambda m: m[0] is not None,
                },
                {
                    "name": "suspicious_script_obfuscation",
                    "description": "Detects obfuscated scripts",
                    "type": "text",
                    "patterns": [
                        (r"eval\(atob\(", None),
                        (r"String\.fromCharCode\([0-9,]+\)", None),
                        (r"\\x[0-9a-fA-F]{2}\\x[0-9a-fA-F]{2}", None),
                    ],
                    "condition": lambda m: any(x is not None for x in m),
                },
                {
                    "name": "suspicious_process_injection",
                    "description": "Detects process injection techniques",
                    "type": "text",
                    "patterns": [
                        (r"VirtualAlloc.*VirtualProtect.*CreateRemoteThread", None),
                        (r"WriteProcessMemory.*CreateRemoteThread", None),
                        (r"NtMapViewOfSection.*NtQueueApcThread", None),
                    ],
                    "condition": lambda m: any(x is not None for x in m),
                },
                {
                    "name": "mimikatz_strings",
                    "description": "Detects Mimikatz-related strings",
                    "type": "text",
                    "patterns": [
                        (r"sekurlsa::", None),
                        (r"kerberos::golden", None),
                        (r"lsadump::", None),
                    ],
                    "condition": lambda m: any(x is not None for x in m),
                },
                {
                    "name": "cobalt_strike_beacon",
                    "description": "Detects CobaltStrike beacon characteristics",
                    "type": "binary",
                    "patterns": [
                        (b"\x00\x01\x00\x01\x00\x02", None),
                        (b"\x69\x68\x69\x68\x69\x6b", None),
                    ],
                    "condition": lambda m: any(x is not None for x in m),
                },
                {
                    "name": "suspicious_execution_flow",
                    "description": "Detects execution flow hiding",
                    "type": "text",
                    "patterns": [
                        (r"setTimeout\(atob\(", None),
                        (r"WScript\.Shell.*\.Run", None),
                        (r"cmd\.exe /c start", None),
                    ],
                    "condition": lambda m: any(x is not None for x in m),
                },
            ]
        )

    def match(self, content, content_type="binary"):
        """Match content against rules"""
        matches = []

        if content_type == "binary" and isinstance(content, str):
            try:
                content = content.encode("utf-8")
            except UnicodeEncodeError:
                content = content.encode("utf-8", errors="ignore")

        if content_type == "text" and isinstance(content, bytes):
            try:
                content = content.decode("utf-8")
            except UnicodeDecodeError:
                content = content.decode("utf-8", errors="ignore")

        for rule in self.rules:
            if rule["type"] != content_type:
                continue

            pattern_matches = []
            for pattern, offset in rule["patterns"]:
                if content_type == "binary":
                    pattern_matches.append(
                        self._binary_search(content, pattern, offset)
                    )
                else:
                    pattern_matches.append(self._text_search(content, pattern))

            if rule["condition"](pattern_matches):
                matches.append(
                    {"rule": rule["name"], "description": rule["description"]}
                )

        return matches

    def _binary_search(self, data, pattern, offset=None):
        """Search for binary pattern at optional offset"""
        if offset is not None:
            # Exact position search
            if len(data) < offset + len(pattern):
                return None
            if data[offset : offset + len(pattern)] == pattern:
                return offset
            return None
        else:
            # Full search
            pos = data.find(pattern)
            return pos if pos != -1 else None

    def _text_search(self, text, pattern):
        """Search for text pattern using regex"""
        match = re.search(pattern, text)
        return match.start() if match else None


class FileAnalyzer:
    """Advanced file analysis without external dependencies"""

    def __init__(self, db_manager, threat_intel):
        self.db = db_manager
        self.threat_intel = threat_intel
        self.signature_engine = SignatureEngine()
        self.recent_files = {}  # Cache of recent file analyses
        self.max_cache_size = 1000
        self.file_magic_db = self._build_magic_db()

    def _build_magic_db(self):
        """Build simplified file magic database"""
        return {
            b"MZ": "PE Executable",
            b"\x7fELF": "ELF Executable",
            b"\xca\xfe\xba\xbe": "Mach-O Binary",
            b"\xcf\xfa\xed\xfe": "Mach-O Binary",
            b"PK\x03\x04": "ZIP Archive",
            b"\x1f\x8b\x08": "GZIP Archive",
            b"\x25PDF": "PDF Document",
            b"\xff\xd8\xff": "JPEG Image",
            b"\x89PNG": "PNG Image",
            b"GIF8": "GIF Image",
            b"#!": "Shell Script",
            b"<?php": "PHP Script",
            b"import": "Python Script",
            b"#!/usr/bin/env python": "Python Script",
            b"<!DOCTYPE html>": "HTML Document",
            b"<html": "HTML Document",
            b"This program cannot be run in DOS mode": "DOS MZ Executable",
            b"#!/bin/sh": "Shell Script",
            b"#!/bin/bash": "Bash Script",
        }

    def analyze(self, file_path):
        """Comprehensive file analysis"""
        if not os.path.exists(file_path) or os.path.isdir(file_path):
            return None

        # Check cache first
        file_key = f"{file_path}:{os.path.getmtime(file_path)}"
        if file_key in self.recent_files:
            return self.recent_files[file_key]

        try:
            # Basic file stats
            stat_info = os.stat(file_path)
            file_size = stat_info.st_size

            # Don't analyze empty or very large files
            if file_size == 0 or file_size > 100 * 1024 * 1024:  # 100MB max
                return None

            # Read file content for analysis (with size limit)
            max_read = min(file_size, 8 * 1024 * 1024)  # 8MB max for content analysis
            with open(file_path, "rb") as f:
                content = f.read(max_read)

            # Determine file type
            file_type = self._determine_file_type(content, file_path)

            # Calculate hashes
            hashes = self._calculate_hashes(content)

            # Check against threat intelligence
            threat_match = any(self.threat_intel.check_hash(h) for h in hashes.values())

            # Perform signature analysis
            signature_matches = self.signature_engine.match(content, "binary")

            # Text-based analysis for script files
            if file_type in ["text", "script", "html", "xml", "json"]:
                try:
                    text_content = content.decode("utf-8", errors="ignore")
                    text_signatures = self.signature_engine.match(text_content, "text")
                    signature_matches.extend(text_signatures)
                except Exception as e:
                    logger.debug(f"Text analysis error on {file_path}: {e}")

            # Special analysis for executables
            pe_info = {}
            if file_type == "pe_executable":
                pe_info = self._analyze_pe(content)

            # Calculate entropy for detecting packed/encrypted content
            entropy = MLHelper.calculate_entropy(content)

            # Assemble analysis results
            analysis = {
                "basic": {
                    "path": file_path,
                    "size": file_size,
                    "type": file_type,
                    "created": stat_info.st_ctime,
                    "modified": stat_info.st_mtime,
                    "accessed": stat_info.st_atime,
                    "owner": stat_info.st_uid,
                    "permissions": stat_info.st_mode,
                    "entropy": entropy,
                    "is_executable": os.access(file_path, os.X_OK),
                },
                "hashes": hashes,
                "threat_intel": {
                    "matches": threat_match,
                    "matched_hash": next(
                        (h for h in hashes.values() if self.threat_intel.check_hash(h)),
                        None,
                    ),
                },
                "signatures": signature_matches,
                "pe_info": pe_info,
                "risk_score": self._calculate_risk_score(
                    file_type, entropy, threat_match, signature_matches, pe_info
                ),
                "timestamp": datetime.utcnow().isoformat(),
            }

            # Limit cache size
            if len(self.recent_files) > self.max_cache_size:
                self.recent_files.pop(next(iter(self.recent_files)))

            # Add to cache
            self.recent_files[file_key] = analysis

            # Report high-risk files
            if analysis["risk_score"] > 70:
                sio_dashboard_client.emit(
                    "file_alert",
                    {
                        "file": file_path,
                        "score": analysis["risk_score"],
                        "type": file_type,
                        "signatures": [sig["rule"] for sig in signature_matches],
                        "entropy": entropy,
                    },
                )

            return analysis
        except Exception as e:
            logger.error(f"File analysis failed for {file_path}: {e}")
            return None

    def _calculate_hashes(self, content):
        """Calculate multiple hash types"""
        return {
            "md5": hashlib.md5(content).hexdigest(),
            "sha1": hashlib.sha1(content).hexdigest(),
            "sha256": hashlib.sha256(content).hexdigest(),
        }

    def _determine_file_type(self, content, file_path):
        """Determine file type from content and extension"""
        # Check by magic bytes first
        for magic, file_type in self.file_magic_db.items():
            if content.startswith(magic):
                if "Executable" in file_type or "Script" in file_type:
                    return file_type.lower().replace(" ", "_")
                return file_type.lower().replace(" ", "_")

        # Check by extension as fallback
        ext = os.path.splitext(file_path)[1].lower()
        ext_map = {
            ".exe": "pe_executable",
            ".dll": "pe_executable",
            ".sys": "pe_executable",
            ".scr": "pe_executable",
            ".bin": "binary",
            ".dat": "data_file",
            ".so": "shared_object",
            ".py": "python_script",
            ".js": "javascript",
            ".ps1": "powershell_script",
            ".vbs": "vbscript",
            ".bat": "batch_script",
            ".cmd": "batch_script",
            ".sh": "shell_script",
            ".html": "html",
            ".htm": "html",
            ".xml": "xml",
            ".json": "json",
            ".txt": "text",
            ".log": "text",
            ".pdf": "pdf_document",
            ".docx": "office_document",
            ".xlsx": "office_document",
            ".pptx": "office_document",
            ".zip": "zip_archive",
            ".tar": "tar_archive",
            ".gz": "gzip_archive",
            ".7z": "7zip_archive",
            ".jar": "java_archive",
            ".apk": "android_package",
        }

        return ext_map.get(ext, "unknown")

    def _analyze_pe(self, content):
        """Basic PE analysis without external dependencies"""
        pe_info = {}

        try:
            # Check for MZ and PE headers
            if not content.startswith(b"MZ"):
                return pe_info

            # Find PE header offset from MZ header
            pe_offset_loc = 0x3C
            if len(content) > pe_offset_loc + 4:
                pe_offset = int.from_bytes(
                    content[pe_offset_loc : pe_offset_loc + 4], byteorder="little"
                )

                # Check PE signature
                if (
                    len(content) > pe_offset + 4
                    and content[pe_offset : pe_offset + 4] == b"PE\0\0"
                ):
                    pe_info["valid_pe"] = True

                    # Get number of sections (offset 6 bytes from PE header)
                    if len(content) > pe_offset + 6 + 2:
                        num_sections = int.from_bytes(
                            content[pe_offset + 6 : pe_offset + 8], byteorder="little"
                        )
                        pe_info["num_sections"] = num_sections

                    # Get timestamp (offset 8 bytes from PE header)
                    if len(content) > pe_offset + 8 + 4:
                        timestamp = int.from_bytes(
                            content[pe_offset + 8 : pe_offset + 12], byteorder="little"
                        )
                        pe_info["timestamp"] = timestamp

                    # Get characteristics (offset 22 bytes from PE header)
                    if len(content) > pe_offset + 22 + 2:
                        characteristics = int.from_bytes(
                            content[pe_offset + 22 : pe_offset + 24], byteorder="little"
                        )
                        pe_info["is_dll"] = bool(characteristics & 0x2000)
                        pe_info["is_system"] = bool(characteristics & 0x1000)
                        pe_info["is_gui"] = bool(characteristics & 0x0002)

                    # Get Optional Header size
                    if len(content) > pe_offset + 20 + 2:
                        opt_header_size = int.from_bytes(
                            content[pe_offset + 20 : pe_offset + 22], byteorder="little"
                        )

                        # Get Subsystem (Windows GUI, Console, etc)
                        if len(content) > pe_offset + 24 + 68 + 2:
                            subsystem = int.from_bytes(
                                content[pe_offset + 24 + 68 : pe_offset + 24 + 70],
                                byteorder="little",
                            )
                            pe_info["subsystem"] = subsystem

                        # Section analysis will require more complex logic
                        pe_info["has_sections_analysis"] = False
        except Exception as e:
            logger.debug(f"PE analysis error: {e}")

        return pe_info

    def _calculate_risk_score(
        self, file_type, entropy, threat_match, signature_matches, pe_info
    ):
        """Calculate file risk score based on multiple factors"""
        score = 0

        # Base score by file type
        high_risk_types = [
            "pe_executable",
            "powershell_script",
            "batch_script",
            "shell_script",
        ]
        medium_risk_types = ["python_script", "javascript", "vbscript", "java_archive"]

        if file_type in high_risk_types:
            score += 30
        elif file_type in medium_risk_types:
            score += 15

        # Entropy score (higher entropy often indicates packing/encryption)
        if entropy > 7.5:  # Very high entropy
            score += 25
        elif entropy > 7.0:
            score += 15
        elif entropy > 6.5:
            score += 10

        # Threat intelligence match is critical
        if threat_match:
            score += 50

        # Signature matches
        score += len(signature_matches) * 15

        # PE characteristics
        if pe_info:
            # Unusual section count
            if pe_info.get("num_sections", 0) > 8:
                score += 15

            # Very recent PE timestamp (could be fake)
            if pe_info.get("timestamp", 0) > time.time() - 86400:
                score += 10

        # Cap the score at 100
        return min(score, 100)

    def scan_directory(self, directory, recursive=True):
        """Scan directory for suspicious files"""
        results = []
        high_risk_files = []

        try:
            walk_fn = os.walk if recursive else lambda d: [(d, os.listdir(d), [])]

            for root, _, files in walk_fn(directory):
                for file in files:
                    file_path = os.path.join(root, file)
                    analysis = self.analyze(file_path)

                    if analysis and analysis["risk_score"] > 50:
                        results.append(analysis)

                        if analysis["risk_score"] > 70:
                            high_risk_files.append(
                                {
                                    "path": file_path,
                                    "score": analysis["risk_score"],
                                    "type": analysis["basic"]["type"],
                                    "signatures": [
                                        sig["rule"] for sig in analysis["signatures"]
                                    ],
                                }
                            )

            # Report scan results
            if high_risk_files:
                sio_dashboard_client.emit(
                    "directory_scan_alert",
                    {
                        "directory": directory,
                        "high_risk_count": len(high_risk_files),
                        "total_scanned": len(results),
                        "high_risk_files": high_risk_files[:10],  # Limit to 10
                    },
                )

            return results
        except Exception as e:
            logger.error(f"Directory scan failed for {directory}: {e}")
            return []


class ProcessMonitor:
    """Advanced process behavior monitoring"""

    def __init__(self, db_manager, threat_intel):
        self.db = db_manager
        self.threat_intel = threat_intel
        self.signature_engine = SignatureEngine()
        self.baseline = {}
        self.process_history = defaultdict(list)  # Historical process info
        self.suspicious_processes = set()
        self.monitored_processes = set()
        self.injection_attempts = defaultdict(int)
        self.lateral_movement = defaultdict(int)
        self.process_tree = defaultdict(list)
        self.dangerous_cmdlines = self._load_dangerous_cmdlines()
        self.stop_event = threading.Event()

    def _load_dangerous_cmdlines(self):
        """Load patterns of dangerous command lines"""
        return [
            # PowerShell obfuscation and encoding
            r"powershell.*-e\s+[A-Za-z0-9+/=]{10,}",
            r"powershell.*-enc.*bypass",
            r"powershell.*downloadstring",
            r"powershell.*-nop.*-w.*hidden",
            r"powershell.*-exec.*bypass",
            # Command download and execution
            r"certutil.*-urlcache.*-f",
            r"bitsadmin.*transfer",
            r"wmic.*os.*get.*process.*call.*create",
            r"regsvr32.*\.dll",
            r"regsvr32.*/i:http",
            r"regsvr32.*/s.*scrobj\.dll",
            # Common LOLBINs (Living Off The Land Binaries)
            r"mshta.*javascript:",
            r"rundll32.*advpack.*RegisterOCX",
            r"rundll32.*setupapi.*InstallHinfSection",
            r"wscript.*vbs",
            r"cscript.*js",
            # Credential access
            r"mimikatz",
            r"procdump.*lsass",
            r"reg.*save.*HKLM\\SAM",
            # Scheduled tasks/persistence
            r"schtasks.*/create",
            r"at.*\\\\.*cmd",
            # Remote execution methods
            r"psexec.*\\\\",
            r"wmic.*node",
            r"wmic.*process.*call.*create",
            # Command obfuscation
            r"cmd.*\^",
            r"cmd.*\|.*\^",
            r"cmd.*\&.*\^",
            # Shell execution variations
            r"sh\s+-c\s+.*\`",
            r"bash\s+-c\s+.*\$\(",
            r"python\s+-c\s+.*exec\(",
            r"perl\s+-e\s+.*system\(",
            # Network utilities for exfil/discovery
            r"netsh.*portproxy",
            r"nc.*-e",
            r"nmap.*-sS",
        ]

    def start(self):
        """Start the monitoring loop in a separate thread"""
        self._establish_baseline()

        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()

        return monitor_thread

    def stop(self):
        """Signal the monitoring thread to stop"""
        self.stop_event.set()

    def _establish_baseline(self):
        """Create a baseline of running processes"""
        try:
            current_processes = self._get_running_processes()

            # Store process information in baseline
            for pid, proc_info in current_processes.items():
                if self._is_system_process(proc_info):
                    self.baseline[pid] = proc_info

            logger.info(
                f"Process baseline established with {len(self.baseline)} system processes"
            )
            return self.baseline
        except Exception as e:
            logger.error(f"Failed to establish process baseline: {e}")
            return {}

    def _monitor_loop(self):
        """Main process monitoring loop"""
        while not self.stop_event.is_set():
            try:
                current_processes = self._get_running_processes()
                self._analyze_processes(current_processes)
                self._update_process_tree(current_processes)
                self._detect_anomalies(current_processes)

                # Sleep between checks
                time.sleep(2)
            except Exception as e:
                logger.error(f"Process monitoring error: {e}")
                time.sleep(5)

    def _get_running_processes(self):
        """Get list of running processes with detailed info"""
        processes = {}

        try:
            process_attrs = [
                "pid",
                "name",
                "exe",
                "cmdline",
                "username",
                "create_time",
                "connections",
                "memory_info",
            ]

            for proc in psutil.process_iter(process_attrs):
                try:
                    pinfo = proc.info
                    pid = pinfo["pid"]

                    # Get additional info
                    try:
                        parent_pid = proc.ppid()
                    except (psutil.AccessDenied, psutil.NoSuchProcess):
                        parent_pid = None

                    # Store process info
                    processes[pid] = {
                        "pid": pid,
                        "name": pinfo["name"],
                        "exe": pinfo["exe"],
                        "cmdline": pinfo["cmdline"],
                        "username": pinfo["username"],
                        "create_time": pinfo["create_time"],
                        "parent": parent_pid,
                        "memory": (
                            pinfo["memory_info"].rss if pinfo["memory_info"] else 0
                        ),
                        "connections": self._get_process_connections(
                            pinfo["connections"]
                        ),
                        "children": [],
                        "anomalies": [],
                    }
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
        except Exception as e:
            logger.error(f"Failed to get running processes: {e}")

        return processes

    def _get_process_connections(self, connections):
        """Format process network connections"""
        if not connections:
            return []

        conn_info = []
        for conn in connections:
            try:
                if conn.status == "ESTABLISHED":
                    conn_info.append(
                        {
                            "local_addr": f"{conn.laddr.ip}:{conn.laddr.port}",
                            "remote_addr": f"{conn.raddr.ip}:{conn.raddr.port}",
                            "status": conn.status,
                            "type": conn.type,
                        }
                    )
            except AttributeError:
                continue

        return conn_info

    def _is_system_process(self, proc_info):
        """Determine if a process is a system process"""
        if not proc_info["exe"]:
            return False

        system_paths = []

        if IS_WINDOWS:
            system_paths = [
                r"C:\\Windows\\System32",
                r"C:\\Windows\\SysWOW64",
                r"C:\\Windows",
            ]
        elif IS_LINUX:
            system_paths = ["/bin", "/sbin", "/usr/bin", "/usr/sbin", "/usr/lib"]
        elif IS_MACOS:
            system_paths = [
                "/bin",
                "/sbin",
                "/usr/bin",
                "/usr/sbin",
                "/usr/libexec",
                "/System/Library",
            ]

        return any(proc_info["exe"].startswith(path) for path in system_paths)

    def _analyze_processes(self, processes):
        """Analyze processes for suspicious behavior"""
        for pid, proc_info in processes.items():
            # Skip previously analyzed processes that are still the same
            if pid in self.monitored_processes:
                continue

            # Flag suspicious command lines
            if proc_info["cmdline"]:
                cmdline = " ".join(proc_info["cmdline"]).lower()
                for pattern in self.dangerous_cmdlines:
                    if re.search(pattern, cmdline, re.IGNORECASE):
                        proc_info["anomalies"].append(f"suspicious_cmdline:{pattern}")
                        self.suspicious_processes.add(pid)
                        break

            # Check for processes running from temp/unusual locations
            suspicious_paths = []
            if IS_WINDOWS:
                suspicious_paths = [
                    r"\\temp\\",
                    r"\\tmp\\",
                    r"\\appdata\\local\\temp\\",
                    r"\\users\\public\\",
                ]
            else:
                suspicious_paths = ["/tmp/", "/var/tmp/", "/dev/shm/", "/var/run/"]

            exe_path = str(proc_info["exe"]).lower() if proc_info["exe"] else ""
            if any(path in exe_path for path in suspicious_paths):
                proc_info["anomalies"].append("suspicious_path")

            # Add to monitored processes
            self.monitored_processes.add(pid)

    def _update_process_tree(self, processes):
        """Build and update process relationship tree"""
        # Clear current tree
        self.process_tree.clear()

        # Build parent-child relationships
        for pid, proc_info in processes.items():
            parent_pid = proc_info["parent"]
            if parent_pid and parent_pid in processes:
                self.process_tree[parent_pid].append(pid)

    def _detect_anomalies(self, current_processes):
        """Detect process behavior anomalies"""
        alerts = []

        # Check for new processes
        for pid, proc_info in current_processes.items():
            # Process started recently (in last check interval)
            if pid not in self.process_history and pid not in self.baseline:
                # Add process to history
                self.process_history[pid] = proc_info

                # Check for unusual parent-child relationships
                parent_pid = proc_info["parent"]
                if parent_pid in current_processes:
                    parent_name = current_processes[parent_pid]["name"].lower()
                    child_name = proc_info["name"].lower()

                    suspicious_parent_child = [
                        # Browser -> unusual process
                        (
                            lambda p: p in ["chrome.exe", "firefox.exe", "msedge.exe"],
                            lambda c: c in ["powershell.exe", "cmd.exe", "wscript.exe"],
                        ),
                        # Office -> script host
                        (
                            lambda p: p
                            in [
                                "excel.exe",
                                "word.exe",
                                "powerpoint.exe",
                                "outlook.exe",
                            ],
                            lambda c: c
                            in [
                                "powershell.exe",
                                "cmd.exe",
                                "wscript.exe",
                                "cscript.exe",
                            ],
                        ),
                        # System process -> unexpected child
                        (
                            lambda p: p in ["svchost.exe", "services.exe", "lsass.exe"],
                            lambda c: c
                            in ["cmd.exe", "powershell.exe", "rundll32.exe"],
                        ),
                    ]

                    for parent_check, child_check in suspicious_parent_child:
                        if parent_check(parent_name) and child_check(child_name):
                            proc_info["anomalies"].append("suspicious_parent_child")
                            alerts.append(
                                {
                                    "type": "suspicious_process",
                                    "severity": "high",
                                    "pid": pid,
                                    "name": proc_info["name"],
                                    "parent": parent_name,
                                    "parent_pid": parent_pid,
                                    "cmdline": (
                                        " ".join(proc_info["cmdline"])
                                        if proc_info["cmdline"]
                                        else ""
                                    ),
                                    "anomaly": "suspicious_parent_child",
                                }
                            )

                # Check command line for malware indicators
                cmdline = (
                    " ".join(proc_info["cmdline"]).lower()
                    if proc_info["cmdline"]
                    else ""
                )
                if cmdline and self.threat_intel.check_pattern(cmdline):
                    proc_info["anomalies"].append("malicious_cmdline_pattern")
                    alerts.append(
                        {
                            "type": "malicious_process",
                            "severity": "critical",
                            "pid": pid,
                            "name": proc_info["name"],
                            "cmdline": cmdline,
                            "anomaly": "malicious_pattern_match",
                        }
                    )

                # Check for network connections to malicious hosts
                for conn in proc_info["connections"]:
                    if "remote_addr" in conn:
                        remote_ip = conn["remote_addr"].split(":")[0]
                        if self.threat_intel.check_ip(remote_ip):
                            proc_info["anomalies"].append(
                                "connection_to_malicious_host"
                            )
                            alerts.append(
                                {
                                    "type": "malicious_connection",
                                    "severity": "critical",
                                    "pid": pid,
                                    "name": proc_info["name"],
                                    "connection": conn["remote_addr"],
                                    "anomaly": "known_bad_host",
                                }
                            )

        # Check for process injection indicators
        self._check_process_injection(current_processes, alerts)

        # Send alerts for detected anomalies
        if alerts:
            for alert in alerts:
                sio_dashboard_client.emit("process_alert", alert)
                self.db.add_alert(
                    alert_type=alert["type"],
                    severity=alert["severity"],
                    source="process_monitor",
                    data=alert,
                )

    def _check_process_injection(self, current_processes, alerts):
        """Check for signs of process injection"""
        if not IS_WINDOWS:
            return  # Currently focused on Windows process injection

        try:
            suspicious_processes = [
                p
                for p in current_processes.values()
                if p["anomalies"] or p["pid"] in self.suspicious_processes
            ]

            for proc_info in suspicious_processes:
                pid = proc_info["pid"]

                try:
                    # Skip if process no longer exists
                    process = psutil.Process(pid)

                    # Check memory regions
                    suspicious_memory = False
                    try:
                        # This is Windows-specific and requires admin rights
                        memory_maps = process.memory_maps()

                        for region in memory_maps:
                            # Check for executable memory regions without mapped files
                            if "x" in region.perms.lower() and not region.path:
                                suspicious_memory = True
                                proc_info["anomalies"].append(
                                    "suspicious_memory_region"
                                )
                                break
                    except psutil.AccessDenied:
                        pass

                    if suspicious_memory:
                        self.injection_attempts[pid] += 1

                        if (
                            self.injection_attempts[pid] >= 3
                        ):  # Confirm with multiple checks
                            alerts.append(
                                {
                                    "type": "process_injection",
                                    "severity": "critical",
                                    "pid": pid,
                                    "name": proc_info["name"],
                                    "cmdline": (
                                        " ".join(proc_info["cmdline"])
                                        if proc_info["cmdline"]
                                        else ""
                                    ),
                                    "anomaly": "memory_injection_detected",
                                }
                            )
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
        except Exception as e:
            logger.warning(f"Process injection check failed: {e}")


class NetworkMonitor:
    """Enhanced network traffic analysis and propagation detection"""

    def __init__(self, db_manager, threat_intel):
        self.db = db_manager
        self.threat_intel = threat_intel
        self.connections = defaultdict(list)  # Track connection history
        self.port_scan_tracking = defaultdict(set)  # Track potential port scans
        self.beaconing_detection = defaultdict(list)  # Track beaconing patterns
        self.dns_cache = {}  # Cache DNS resolutions
        self.connection_counts = Counter()  # Count connections per destination
        self.propagation_attempts = defaultdict(list)  # Track lateral movement
        self.outbound_blocklist = set()  # Dynamic outbound block list
        self.stop_event = threading.Event()

    def start(self):
        """Start network monitoring in a separate thread"""
        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()

        return monitor_thread

    def stop(self):
        """Signal the monitoring thread to stop"""
        self.stop_event.set()

    def _monitor_loop(self):
        """Main network monitoring loop"""
        while not self.stop_event.is_set():
            try:
                # Get current network connections
                connections = self._get_current_connections()

                # Analyze for suspicious patterns
                self._analyze_connections(connections)

                # Detect potential port scans
                self._detect_port_scans()

                # Detect beaconing patterns
                self._detect_beaconing()

                # Detect lateral movement
                self._detect_lateral_movement(connections)

                # Sleep between checks
                time.sleep(3)
            except Exception as e:
                logger.error(f"Network monitoring error: {e}")
                time.sleep(5)

    def _get_current_connections(self):
        """Get current network connections across the system"""
        connections = []

        try:
            # Get all network connections
            for conn in psutil.net_connections(kind="all"):
                try:
                    if not conn.raddr:  # No remote address (listening socket)
                        continue

                    # Get process info
                    try:
                        process = psutil.Process(conn.pid)
                        process_name = process.name()
                        process_exe = process.exe()
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        process_name = "unknown"
                        process_exe = None

                    # Add connection info
                    connections.append(
                        {
                            "pid": conn.pid,
                            "process": process_name,
                            "exe": process_exe,
                            "proto": self._get_proto_name(conn.type),
                            "local_addr": (
                                f"{conn.laddr.ip}:{conn.laddr.port}"
                                if conn.laddr
                                else None
                            ),
                            "remote_addr": (
                                f"{conn.raddr.ip}:{conn.raddr.port}"
                                if conn.raddr
                                else None
                            ),
                            "remote_ip": conn.raddr.ip if conn.raddr else None,
                            "remote_port": conn.raddr.port if conn.raddr else None,
                            "status": conn.status,
                            "timestamp": time.time(),
                        }
                    )
                except (AttributeError, IndexError):
                    continue
        except Exception as e:
            logger.error(f"Failed to get network connections: {e}")

        return connections

    def _get_proto_name(self, proto_num):
        """Convert protocol number to name"""
        if proto_num == socket.SOCK_STREAM:
            return "TCP"
        elif proto_num == socket.SOCK_DGRAM:
            return "UDP"
        else:
            return str(proto_num)

    def _analyze_connections(self, connections):
        """Analyze network connections for suspicious activity"""
        alerts = []

        for conn in connections:
            # Skip connections with no remote IP
            if not conn["remote_ip"]:
                continue

            # Check threat intelligence for known bad IPs
            if self.threat_intel.check_ip(conn["remote_ip"]):
                alerts.append(
                    {
                        "type": "malicious_connection",
                        "severity": "high",
                        "process": conn["process"],
                        "pid": conn["pid"],
                        "connection": conn["remote_addr"],
                        "protocol": conn["proto"],
                        "reason": "known_bad_ip",
                        "timestamp": datetime.utcnow().isoformat(),
                    }
                )

                # Add to outbound blocklist
                self.outbound_blocklist.add(conn["remote_ip"])

            # Check known malicious ports
            malicious_ports = {
                4444: "metasploit_default",
                8000: "common_backdoor",
                8080: "potential_c2",
                8443: "potential_c2_ssl",
                9001: "potential_tor",
                31337: "elite_backdoor",
            }

            if conn["remote_port"] in malicious_ports:
                alerts.append(
                    {
                        "type": "suspicious_connection",
                        "severity": "medium",
                        "process": conn["process"],
                        "pid": conn["pid"],
                        "connection": conn["remote_addr"],
                        "protocol": conn["proto"],
                        "reason": f"suspicious_port_{malicious_ports[conn['remote_port']]}",
                        "timestamp": datetime.utcnow().isoformat(),
                    }
                )

            # Track connection for beaconing detection
            conn_key = f"{conn['pid']}:{conn['remote_addr']}"
            self.beaconing_detection[conn_key].append(conn["timestamp"])

            # Limit history size
            if len(self.beaconing_detection[conn_key]) > 20:
                self.beaconing_detection[conn_key] = self.beaconing_detection[conn_key][
                    -20:
                ]

            # Track connection counts
            self.connection_counts[conn["remote_ip"]]
